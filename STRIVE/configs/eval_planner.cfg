
# save options
out: ./out/eval_planner_out

# data options
data_dir: ./data/nuscenes
data_version: trainval
# same as in adversarial optimization
split: val
val_size: 400     
random_val: True
seq_interval: 10

shuffle: False

# adversarial scenarios to run on
# scenario_dir: ./out/adv_gen_rule_based_out/scenario_results/adv_sol_success
scenario_dir: ./out/adv_gen_rule_based_out_1728564449/scenario_results/adv_sol_success

skip_regular: False
filter_regular: True # only evaluate on "regular" scenarios that were used to initialize the given accident scenarios

#
# planner config
#
eval_replay_planner: False # change to True to evaluate "replay" planner instead of rule-based
# planner configuration to evaluate
#       see planners/hardcode_goalcond_nusc.py
planner_dt: 0.2
planner_preddt: 0.2
planner_nsteps: 25
planner_cdistang: 20.0
planner_xydistmax: 2.0
planner_smax: 15.0
planner_accmax: 3.0
planner_predsfacs: [0.5, 1.0]
planner_predafacs: [0.5]
planner_interacdist: 70.0
planner_planaccfacs: [1.0]
planner_plannspeeds: 5
planner_col_plim: 0.1
planner_score_wmin: 0.7
planner_score_wfac: 0.05
